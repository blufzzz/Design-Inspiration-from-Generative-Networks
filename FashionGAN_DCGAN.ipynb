{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "import os\n",
    "import ast\n",
    "import skimage\n",
    "import imageio\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from math import log10\n",
    "import easydict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import re\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from skimage import segmentation\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from shutil import rmtree\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "from torch import autograd\n",
    "\n",
    "from skimage import io\n",
    "from skimage.feature import canny\n",
    "from skimage.morphology import dilation, disk\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from utils import vis_batch, collate_fn, tensor2numpy\n",
    "from encoder_decoder import MaskDecoder, MaskEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionEdgesDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 images_fold, \n",
    "                 attr_file=None, \n",
    "                 check_corrupted=False, \n",
    "                 return_mask=True):\n",
    "        \n",
    "        self.corrupted_images = set()\n",
    "        self.check_corrupted = check_corrupted\n",
    "        self.images_fold = images_fold\n",
    "        \n",
    "        if attr_file is not None:\n",
    "            images2attr_dict = {}\n",
    "            with open(attr_file, 'r') as f:\n",
    "                dicts = f.readlines()\n",
    "            for d in tqdm_notebook(dicts):\n",
    "                dct = ast.literal_eval(d)\n",
    "                image_name = dct['image']\n",
    "                \n",
    "                if check_corrupted:\n",
    "                    img = Image.open(os.path.join(self.images_fold, image_name))\n",
    "                    if not self._is_appropriate(np.array(img)):\n",
    "                        self.corrupted_images.add(image_name)\n",
    "                        continue\n",
    "\n",
    "                images2attr_dict[image_name] = dct['attributes']\n",
    "                \n",
    "            self.images2attr = images2attr_dict\n",
    "            self.images_names = list(images2attr_dict.keys())\n",
    "        else:\n",
    "            self.images_names = os.listdir(self.images_fold)\n",
    "\n",
    "        \n",
    "    def _is_appropriate(self, img, thresh = 10):\n",
    "    \n",
    "        return np.all(img[:thresh,:thresh] == 255)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.images_names[idx]\n",
    "        img = Image.open(os.path.join(self.images_fold, image_name))#.convert('RGB')        \n",
    "        if not self.check_corrupted and not self._is_appropriate(np.array(img)):\n",
    "            return None\n",
    "        \n",
    "        img = Resize((128, 128))(img)\n",
    "        \n",
    "        img = ToTensor()(img)\n",
    "        if img.shape[0] > 3:\n",
    "            img = img[:3]\n",
    "        \n",
    "        edges = self._image2edges(tensor2numpy(img))\n",
    "        \n",
    "        return torch.tensor(edges, dtype=torch.float32).unsqueeze(0), img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2edges(image, low_thresh=0.05, high_thresh=0.3, sigma=0.1, selem=True, d = 1.5):\n",
    "        '''\n",
    "        image - np.array\n",
    "        '''\n",
    "        image_gray_rescaled = rgb2gray(image)\n",
    "        edges = canny(image_gray_rescaled, sigma = sigma, low_threshold=low_thresh, high_threshold=high_thresh)\n",
    "        if selem:\n",
    "            selem = disk(d)\n",
    "            edges = dilation(edges, selem)\n",
    "  \n",
    "        return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/ibulygin/.torch/models/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 574673361/574673361 [00:12<00:00, 45817192.87it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mode = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a970828100fe4824983d3d124217595d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14221), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "names = os.listdir('./cp-vton/')\n",
    "# edges = []\n",
    "# images = []\n",
    "# for name in tqdm_notebook(names):\n",
    "#     img =plt.imread('./cp-vton/'+name)\n",
    "#     images.append(ToTensor()(img))\n",
    "#     edge = image2edges(img)\n",
    "#     edges.append(torch.tensor(edge.astype(float), dtype=torch.float32).unsqueeze(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7369dec0b9948db8864d8c2cb4ff1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14221), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "shapes = []\n",
    "for image in tqdm_notebook(edges):\n",
    "    image = image[0].numpy()\n",
    "    h,w = image.shape\n",
    "    shape = segmentation.flood(gaussian(image,0.2),\n",
    "                                  seed_point=(0, 0))\n",
    "    \n",
    "    shapes.append(shape)\n",
    "    \n",
    "#     fig, axes = plt.subplots(ncols=2, nrows=1)\n",
    "#     axes[0].imshow(image)\n",
    "#     axes[0].set_title('Edges')\n",
    "#     axes[1].imshow(shape)\n",
    "#     axes[1].set_title('After Gaussian filter and Flood')\n",
    "    \n",
    "#     axes[0].set_xticks([])\n",
    "#     axes[0].set_yticks([])\n",
    "#     axes[1].set_xticks([])\n",
    "#     axes[1].set_yticks([])\n",
    "    \n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
